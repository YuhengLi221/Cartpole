{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This program could achieve the goal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global parameters\n",
    "dims_obs=(1, 1, 6, 12,)\n",
    "min_lr=0.1\n",
    "min_epsilon=0.1\n",
    "discount=1\n",
    "up_limits = [env.observation_space.high[0], 0.4, env.observation_space.high[2], math.radians(40)]\n",
    "low_limits =[env.observation_space.low[0], -0.4, env.observation_space.low[2], -math.radians(40)]\n",
    "Q_table = np.zeros(dims_obs + (2,)) # the number of action is 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_discretizer(obs):\n",
    "    ratios = [(obs[i] + abs(low_limits[i])) / (up_limits[i] - low_limits[i]) for i in range(len(obs))]\n",
    "    new_obs = [round((dims_obs[i] - 1) * ratios[i]) for i in range(len(obs))]\n",
    "    new_obs = [min(dims_obs[i] - 1, max(0, new_obs[i])) for i in range(len(obs))]\n",
    "\n",
    "    new_obs = tuple(map(int, new_obs))\n",
    "    return new_obs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(e):\n",
    "    temp=1-math.log10( (e+1)/25 )\n",
    "    return max( min_lr,  min(1,temp)  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epsilon(e):\n",
    "    temp=1-math.log10( (e+1)/25 )\n",
    "    return max( min_epsilon, min(1,temp)  )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_Q(old_state, new_state, reward, action, lr):\n",
    "    max_value = max(Q_table[tuple(new_state)])\n",
    "    update = reward + discount * max_value - Q_table[tuple(old_state)][action]\n",
    "    Q_table[tuple(old_state)][action]+=lr*update\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(state, epsilon):\n",
    "    if (np.random.random() <= epsilon):\n",
    "        return env.action_space.sample() #exploration\n",
    "    else:\n",
    "        return np.argmax(Q_table[state])#exploitation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(episodes):\n",
    "    \n",
    "        scores=[]\n",
    "        avg=0\n",
    "        \n",
    "        for episode in range(episodes):     \n",
    "            continuous_state = env.reset()\n",
    "            current_state = state_discretizer(continuous_state)\n",
    "            lr= get_lr(episode)\n",
    "            epsilon = get_epsilon(episode)\n",
    "            \n",
    "            done=False # initial value of done before game start\n",
    "            i=0\n",
    "            while not done:\n",
    "                i+=1\n",
    "                action = select_action( current_state, epsilon )\n",
    "                obs, reward, done, _ = env.step(action)\n",
    "                new_state = state_discretizer(obs)\n",
    "                update_Q(current_state, new_state, reward, action, lr)\n",
    "                current_state = new_state\n",
    "            \n",
    "            scores.append(i)\n",
    "            \n",
    "\n",
    "        \n",
    "        for i in range(399,98,-1):\n",
    "            if sum(scores[i-99:i+1])>(195*100):\n",
    "                label=i\n",
    "           \n",
    "        print(scores)\n",
    "        print('the average score of last consecutive 100 episodes is',sum(scores[300:400])/100)        \n",
    "        print('This model could encounter 100 consecutive episodes with an average score of above 195 at the ',label,'th episode')\n",
    "                \n",
    "                \n",
    "            \n",
    "\n",
    "            #print(i)\n",
    "      \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 10, 18, 12, 23, 55, 21, 16, 24, 18, 14, 17, 17, 34, 25, 13, 10, 24, 39, 10, 49, 62, 13, 20, 17, 13, 37, 24, 13, 38, 20, 18, 16, 25, 31, 12, 17, 19, 28, 27, 24, 14, 19, 21, 21, 15, 19, 19, 13, 67, 27, 15, 12, 20, 29, 50, 34, 18, 21, 16, 21, 43, 30, 40, 80, 17, 36, 50, 17, 10, 13, 75, 125, 48, 46, 50, 10, 43, 83, 41, 23, 12, 23, 21, 31, 43, 17, 143, 28, 20, 61, 18, 60, 29, 29, 68, 99, 50, 52, 40, 51, 39, 29, 49, 32, 32, 11, 24, 37, 26, 82, 104, 93, 23, 109, 49, 38, 30, 43, 20, 24, 194, 69, 119, 45, 123, 61, 50, 322, 500, 388, 458, 456, 262, 246, 322, 259, 245, 500, 367, 376, 309, 500, 180, 148, 209, 500, 170, 215, 500, 293, 225, 256, 93, 298, 500, 500, 500, 500, 500, 264, 500, 500, 500, 496, 400, 500, 500, 500, 500, 500, 500, 358, 429, 442, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 444, 500, 500, 500, 467, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 376, 500, 500, 500, 500, 463, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 333, 324, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 383, 500, 500, 500, 500, 500, 500, 472, 412, 500, 500, 500, 500, 500, 500, 500, 500, 276, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 421, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 274, 500, 500, 402, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 455, 500, 425, 500, 500, 298, 500, 500, 486, 500, 500, 500, 500, 456, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 476, 500, 500, 500, 500, 500, 500, 500, 500, 275]\n",
      "the average score of last consecutive 100 episodes is 489.68\n",
      "This model could encounter 100 consecutive episodes with an average score of above 195 at the  171 th episode\n"
     ]
    }
   ],
   "source": [
    "train(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
